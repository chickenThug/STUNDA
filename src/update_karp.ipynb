{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from utils import get_all, add_entry, add_entries, delete_entry_by_id, get_swe_inflections, add_inflections, get_eng_inflections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = get_all()\n",
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = json.dumps(json_data, indent=4)  # Add indentation for readability\n",
    "\n",
    "# Specify the file path where you want to save the JSON data\n",
    "file_path = \"karp_og_data.json\"\n",
    "\n",
    "# Write JSON data to file\n",
    "with open(\"../../public_data/\" + file_path, 'w') as file:\n",
    "    file.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = json_data[\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authorization = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJpc3MiOiJodHRwczovL3NwLnNwcmFha2Jhbmtlbi5ndS5zZS9hdXRoL2p3dCIsImlhdCI6MTcxNTU1ODI0MCwiZXhwIjoxNzE1NjAxNDQwLCJqdGkiOiI2NWY2M2I1NDlhNTA0MmVhOTY2ZWRjM2Q0ZmMwYzk1OCIsImlkcCI6Imh0dHBzOi8vc2FtbC5zeXMua3RoLnNlL2lkcC9zaGliYm9sZXRoIiwic3ViIjoidmlnZ29zQGt0aC5zZSIsIm5hbWUiOiJWaWdnbyBTdlx1MDBlNHJka3JvbmEiLCJlbWFpbCI6InZpZ2dvc0BrdGguc2UiLCJhZmZpbGlhdGlvbiI6InN0dWRlbnRAa3RoLnNlO3N0YWZmQGt0aC5zZTttZW1iZXJAa3RoLnNlO2VtcGxveWVlQGt0aC5zZSIsInNjb3BlIjp7ImxleGljYSI6eyJzdHVuZGEiOjEwfX0sImxldmVscyI6eyJSRUFEIjoxLCJXUklURSI6MTAsIkFETUlOIjoxMDB9fQ.QdQG4bvuSgbLhOYbD-kwaDLst0NlxMAEcc4_jNnvE3Z7jpqO_3k2vepUZaiGOd-daU64m3Hkit6RZrkRf1Vc_BizzpEu6tE5aCA4RnFXnIKP--R2upH9eBgl7Q0DIS135aEHDsBLk_SuhiPKG37Gy3ELzkZQa7p4IeCUMkMMyeN0F5GguExjAMyp4Ae45nUutWVXQuSo2vw6b5I2gtjelafUfVKZyf4lGAvszZYK9k65u_gPHiqa4_wmSbvZ4FFaVOtuF7-otjm2WFuQqLIuEWljiuQGRu7lZ2BdpbCrVACpJQ1dS_8SoecjFLyA31N9Xuk0HXSSRW65fHD7twH7dg\"\n",
    "for entry in entries:\n",
    "    entry_data = entry[\"entry\"]\n",
    "    src_info = entry[\"entry\"][\"src\"]\n",
    "    renamed_source = src_info.replace(\"paired_keywords\", \"PK\")\n",
    "    entry[\"entry\"][\"src\"] = renamed_source\n",
    "    if src_info != renamed_source:\n",
    "        add_inflections(entry[\"id\"], authorization, entry_data, entry[\"version\"], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authorization = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJpc3MiOiJodHRwczovL3NwLnNwcmFha2Jhbmtlbi5ndS5zZS9hdXRoL2p3dCIsImlhdCI6MTcxNzExNjU2MiwiZXhwIjoxNzE3MTU5NzYyLCJqdGkiOiI3MmY3ZTllNzk3ZTU0YjFjODJlYWJhZDg1ODYzNWQyMSIsImlkcCI6Imh0dHBzOi8vc2FtbC5zeXMua3RoLnNlL2lkcC9zaGliYm9sZXRoIiwic3ViIjoidmlnZ29zQGt0aC5zZSIsIm5hbWUiOiJWaWdnbyBTdlx1MDBlNHJka3JvbmEiLCJlbWFpbCI6InZpZ2dvc0BrdGguc2UiLCJhZmZpbGlhdGlvbiI6InN0dWRlbnRAa3RoLnNlO3N0YWZmQGt0aC5zZTttZW1iZXJAa3RoLnNlO2VtcGxveWVlQGt0aC5zZSIsInNjb3BlIjp7ImxleGljYSI6eyJzdHVuZGEiOjEwfX0sImxldmVscyI6eyJSRUFEIjoxLCJXUklURSI6MTAsIkFETUlOIjoxMDB9fQ.aUvMy5X1pNDOTJ5LcBqo8lXaMzKC8g8g4LgF2GW5JJvNrkrqkTG1HZtzzu_qDwm7V8PMJZIf5rN-ew6F6M1w0AaCel-r2ahB_twsM1a5P1duWO5MLeJ_NMdp2B7XHDNLOx7V9B9cfrPez-igD1pZgAzHI9FMIJDBH3mgn0ywUpVz1UFhGDbHRcnHObI_js4XKDrRShje-QNGwD2iGXIuLkPadHnJP5MWvIXEvpH6TLw3_Uhg64Sc1tXkEAbloZiKyZwA6M8oSTENCDLnbB7zTHfi2PlEUVn_K8hOUUdItqYXGUdzIfdQLEjLTpBzTpc_c_QAfhvKKGjvIE3XNEcJAg\"\n",
    "for entry in entries:\n",
    "    entry_data = entry[\"entry\"]\n",
    "    lemma = entry[\"entry\"][\"swe\"][\"lemma\"]\n",
    "    inflections = entry[\"entry\"][\"swe\"].get(\"inflection\", [])\n",
    "    new_inflections = []\n",
    "    alter = False\n",
    "    for inflection in inflections:\n",
    "        if \"-\" in inflection and not \"-\" in lemma:\n",
    "            new_inflections.append(inflection.split(\"-\")[1])\n",
    "            alter = True\n",
    "    \n",
    "    if alter:\n",
    "        entry[\"entry\"][\"swe\"][\"inflection\"] = new_inflections\n",
    "        print(entry_data)    \n",
    "        add_inflections(entry[\"id\"], authorization, entry_data, entry[\"version\"], False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "authorization = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJpc3MiOiJodHRwczovL3NwLnNwcmFha2Jhbmtlbi5ndS5zZS9hdXRoL2p3dCIsImlhdCI6MTcxNDY3MTA3MSwiZXhwIjoxNzE0NzE0MjcxLCJqdGkiOiJhNzI3MjQ3NTdlMzE0ZjE5ODVkNzBhMjIzNDEwOTU3NiIsImlkcCI6Imh0dHBzOi8vc2FtbC5zeXMua3RoLnNlL2lkcC9zaGliYm9sZXRoIiwic3ViIjoidmlnZ29zQGt0aC5zZSIsIm5hbWUiOiJWaWdnbyBTdlx1MDBlNHJka3JvbmEiLCJlbWFpbCI6InZpZ2dvc0BrdGguc2UiLCJhZmZpbGlhdGlvbiI6InN0dWRlbnRAa3RoLnNlO3N0YWZmQGt0aC5zZTttZW1iZXJAa3RoLnNlO2VtcGxveWVlQGt0aC5zZSIsInNjb3BlIjp7ImxleGljYSI6eyJzdHVuZGEiOjEwfX0sImxldmVscyI6eyJSRUFEIjoxLCJXUklURSI6MTAsIkFETUlOIjoxMDB9fQ.yingJCvf5579yTN85bRjnTKmkfSobVfjAqndzitr11TjCQKl5DAtLyrcQBsRAMCev6nGTI1PpzGqKC6q38f5hSOw0knp2b4jhp0khT2W_NNl8M3CH2QWrt1YD6ozxkGOwkDfd5kZZqOw72qirOgyK6FBjDeOLcsgU_2eWKqHOrkrgLXeP_fRT5JUwwfudVIEfHtxPK0mXYCPxUCh-PKjBobS1VNt5DFzdkFQidYxqDJksWGJlfGJNnGxPsS_kzsFo4lX4MLSKP657ycWkfrrTAjvf_uyzmRd25xk-4NLS4PXxwm1ulLXUzk2fAlcuOOMUAS7kqiM3gjvgSeZsoesfw\"\n",
    "for entry in entries:\n",
    "    entry_data = entry[\"entry\"]\n",
    "    karp_inflections = []\n",
    "    if entry_data[\"pos\"] == \"N\":\n",
    "        inflections = get_swe_inflections(entry_data[\"swe\"][\"lemma\"])\n",
    "        if not type(inflections) == list:\n",
    "            continue\n",
    "        for inflection in inflections:\n",
    "            if inflection.get(\"msd\", \"\") == \"pl indef nom\":\n",
    "                karp_inflections.append(inflection.get(\"writtenForm\", \"\"))\n",
    "    elif entry_data[\"pos\"] == \"V\":\n",
    "        inflections = get_swe_inflections(entry_data[\"swe\"][\"lemma\"])\n",
    "        if not type(inflections) == list:\n",
    "            continue\n",
    "        for inflection in inflections:\n",
    "            if inflection.get(\"msd\", \"\") in [\"pres ind aktiv\", \"pret ind aktiv\", \"sup aktiv\"]:\n",
    "                karp_inflections.append(inflection.get(\"writtenForm\", \"\"))\n",
    "    elif entry_data[\"pos\"] in  [\"A\", \"Ab\"]:\n",
    "        inflections = get_swe_inflections(entry_data[\"swe\"][\"lemma\"])\n",
    "        if not type(inflections) == list:\n",
    "            continue\n",
    "        if inflection.get(\"msd\", \"\") in [\"pos indef sg u nom\", \"pos indef sg n nom\", \"pos indef pl nom\"]:\n",
    "            karp_inflections.append(inflection.get(\"writtenForm\", \"\"))\n",
    "    if karp_inflections:\n",
    "        entry_data[\"swe\"][\"inflection\"] = karp_inflections\n",
    "        add_inflections(entry[\"id\"], authorization, entry_data, entry[\"version\"], True)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "authorization = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJpc3MiOiJodHRwczovL3NwLnNwcmFha2Jhbmtlbi5ndS5zZS9hdXRoL2p3dCIsImlhdCI6MTcxNDczNjE3MiwiZXhwIjoxNzE0Nzc5MzcyLCJqdGkiOiI1MjdkNGVmZjBjMDE0MWM2ODExZGRmMzdkMmFmM2ZhNiIsImlkcCI6Imh0dHBzOi8vc2FtbC5zeXMua3RoLnNlL2lkcC9zaGliYm9sZXRoIiwic3ViIjoidmlnZ29zQGt0aC5zZSIsIm5hbWUiOiJWaWdnbyBTdlx1MDBlNHJka3JvbmEiLCJlbWFpbCI6InZpZ2dvc0BrdGguc2UiLCJhZmZpbGlhdGlvbiI6InN0dWRlbnRAa3RoLnNlO3N0YWZmQGt0aC5zZTttZW1iZXJAa3RoLnNlO2VtcGxveWVlQGt0aC5zZSIsInNjb3BlIjp7ImxleGljYSI6eyJzdHVuZGEiOjEwfX0sImxldmVscyI6eyJSRUFEIjoxLCJXUklURSI6MTAsIkFETUlOIjoxMDB9fQ.s5h9FiXSQDBbystff9zMhESOu2JF4UzRusuZI5AaNio-VQ-ASbXmTOiNeFhGibCAOMBbLStwZ7aCke5uRGakygYuMlpLH7QH36TwqXq-fD9PxoF8mm8Qd8r6EOyKJtJFTghKhss3_PLC0Vm5TYg_d7jlPgST09enp5kPy1PsEEkjPx6y8VUQKZHZDpIDYRWHLM4-u9vxpuX46xweAJow0hogMD_MT8-WXIH2UyG7ShOzrTFVmTkYyEWKcUavuwo-bP2a24hrEOedkNOI6vfCmNVC5u70d6pD7UWwD5JmLcnswfKac_erhXcsc-gnJH47RiN4uEX7vbOI3YX10tgfqQ\"\n",
    "for entry in entries:\n",
    "    entry_data = entry[\"entry\"]\n",
    "    karp_inflections = []\n",
    "    if entry_data[\"pos\"] == \"N\":\n",
    "        inflections = get_eng_inflections(entry_data[\"eng\"][\"lemma\"], \"NOUN\")\n",
    "        if \"NNS\" in inflections:\n",
    "            karp_inflections.append(inflections.get(\"NNS\", \"\")[0])\n",
    "    elif entry_data[\"pos\"] == \"V\":\n",
    "        inflections = get_eng_inflections(entry_data[\"eng\"][\"lemma\"], \"VERB\")\n",
    "        if \"VBG\" in inflections:\n",
    "            karp_inflections.append(inflections.get(\"VBG\", \"\")[0])\n",
    "        if \"VBN\" in inflections:\n",
    "            karp_inflections.append(inflections.get(\"VBN\", \"\")[0])\n",
    "        if \"VBD\" in inflections:\n",
    "            karp_inflections.append(inflections.get(\"VBD\", \"\")[0])\n",
    "    if karp_inflections:\n",
    "        entry_data[\"eng\"][\"inflection\"] = karp_inflections\n",
    "        add_inflections(entry[\"id\"], authorization, entry_data, entry[\"version\"], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = json_data[\"hits\"]\n",
    "print(len(entries))\n",
    "\n",
    "# authorization = json.load(open('../../data/secrets.json')).get(\"jwt_token\", \"\")\n",
    "\n",
    "authorization = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJpc3MiOiJodHRwczovL3NwLnNwcmFha2Jhbmtlbi5ndS5zZS9hdXRoL2p3dCIsImlhdCI6MTcxNDQyNjAxMSwiZXhwIjoxNzE0NDY5MjExLCJqdGkiOiJmN2M3OTY2ZWE5MjI0ZWU3OWZmMGQyMjI1OTkwNzM5ZiIsImlkcCI6Imh0dHBzOi8vc2FtbC5zeXMua3RoLnNlL2lkcC9zaGliYm9sZXRoIiwic3ViIjoidmlnZ29zQGt0aC5zZSIsIm5hbWUiOiJWaWdnbyBTdlx1MDBlNHJka3JvbmEiLCJlbWFpbCI6InZpZ2dvc0BrdGguc2UiLCJhZmZpbGlhdGlvbiI6InN0dWRlbnRAa3RoLnNlO3N0YWZmQGt0aC5zZTttZW1iZXJAa3RoLnNlO2VtcGxveWVlQGt0aC5zZSIsInNjb3BlIjp7ImxleGljYSI6eyJzdHVuZGEiOjEwfX0sImxldmVscyI6eyJSRUFEIjoxLCJXUklURSI6MTAsIkFETUlOIjoxMDB9fQ.A68n86liGSu-BIL_y8ApH5y8Oc3AroPxohxS2YU6dov0hKrjVk3S3wtt3omRs2RBb77kpeBumzrr8zc9N9Dwfi98fqMTPioTOmSqgAErNEzefdXiycAedytq1wCxoGHQzrtck25eJtlese3I33Jtv7ngvSlyBfBB4P-NSVNlAv1UaLQUbW3siplOgW1rinkexEYwCF0ty7KSXemoO9qNP-qS5jDu_vjC6vfTQFavgwCOPKCwCOpsEJq44ADu25P2lJ_MjcHEWPxkZOMWiJORoTGi1LsFYKCpYmoerI4YyntmgA_cZxsdLJ6rFSLlqoqoPJ9lSe6yrKMbGcX-sGFoyQ\"\n",
    "\n",
    "deleted = 0\n",
    "print(authorization)\n",
    "for index, entry in enumerate(entries):\n",
    "    id = entry[\"id\"]\n",
    "    res = delete_entry_by_id(id, authorization)\n",
    "    \n",
    "    deleted = deleted + 1 if res else deleted \n",
    "    if index % 500 == 0:\n",
    "        print(f\"processed {index+1} requests of which {deleted} were sucessfull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"../\"\n",
    "file = \"ready_for_karp_v3.csv\"\n",
    "file2 = \"ready_for_karp_v2.csv\"\n",
    "\n",
    "df = pd.read_csv(path+file)\n",
    "df2 = pd.read_csv(path+file2)\n",
    "\n",
    "df = df[df[\"status\"] == \"automatically verified\"].copy()\n",
    "df2 = df2[df2[\"status\"] == \"automatically verified\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"src\"] = \"paired_keywords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df, df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"../../\"\n",
    "file = \"ready_for_karp2.csv\"\n",
    "\n",
    "df2 = pd.read_csv(path+file)\n",
    "\n",
    "df2 = df2[df2[\"status\"] == \"automatically verified\"].copy().drop_duplicates()\n",
    "\n",
    "\n",
    "df2 = df2.groupby([\"English lemma\", \"POS\", \"status\"])[\"Swedish lemma\"].agg(lambda x: ';'.join(x)).reset_index()\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates in-place\n",
    "df3.drop_duplicates(subset=[\"Swedish lemma\", \"English lemma\", \"POS\", \"src\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df3.groupby([\"English lemma\", \"POS\", \"Swedish lemma\"])[\"src\"].agg(lambda x: ', '.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts = grouped_df.to_dict(orient='records')\n",
    "new_list = []\n",
    "for item in list_of_dicts:\n",
    "    new_item = {\n",
    "        \"eng\": {\n",
    "            \"lemma\": item[\"English lemma\"]\n",
    "        },\n",
    "        \"swe\": {\n",
    "            \"lemma\": item[\"Swedish lemma\"]\n",
    "        },\n",
    "        \"src\": item[\"src\"],\n",
    "        \"pos\": item[\"POS\"]\n",
    "    }\n",
    "    new_list.append(new_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "added = 0\n",
    "authorization = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJpc3MiOiJodHRwczovL3NwLnNwcmFha2Jhbmtlbi5ndS5zZS9hdXRoL2p3dCIsImlhdCI6MTcxNDQyNjAxMSwiZXhwIjoxNzE0NDY5MjExLCJqdGkiOiJmN2M3OTY2ZWE5MjI0ZWU3OWZmMGQyMjI1OTkwNzM5ZiIsImlkcCI6Imh0dHBzOi8vc2FtbC5zeXMua3RoLnNlL2lkcC9zaGliYm9sZXRoIiwic3ViIjoidmlnZ29zQGt0aC5zZSIsIm5hbWUiOiJWaWdnbyBTdlx1MDBlNHJka3JvbmEiLCJlbWFpbCI6InZpZ2dvc0BrdGguc2UiLCJhZmZpbGlhdGlvbiI6InN0dWRlbnRAa3RoLnNlO3N0YWZmQGt0aC5zZTttZW1iZXJAa3RoLnNlO2VtcGxveWVlQGt0aC5zZSIsInNjb3BlIjp7ImxleGljYSI6eyJzdHVuZGEiOjEwfX0sImxldmVscyI6eyJSRUFEIjoxLCJXUklURSI6MTAsIkFETUlOIjoxMDB9fQ.A68n86liGSu-BIL_y8ApH5y8Oc3AroPxohxS2YU6dov0hKrjVk3S3wtt3omRs2RBb77kpeBumzrr8zc9N9Dwfi98fqMTPioTOmSqgAErNEzefdXiycAedytq1wCxoGHQzrtck25eJtlese3I33Jtv7ngvSlyBfBB4P-NSVNlAv1UaLQUbW3siplOgW1rinkexEYwCF0ty7KSXemoO9qNP-qS5jDu_vjC6vfTQFavgwCOPKCwCOpsEJq44ADu25P2lJ_MjcHEWPxkZOMWiJORoTGi1LsFYKCpYmoerI4YyntmgA_cZxsdLJ6rFSLlqoqoPJ9lSe6yrKMbGcX-sGFoyQ\"\n",
    "for j, entry in enumerate(new_list):\n",
    "    \n",
    "    res = add_entry(authorization, entry)\n",
    "    \n",
    "    if res is not None:\n",
    "        added += 1\n",
    "\n",
    "    if j % 300 == 0:\n",
    "        print(added, j+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"../../\"\n",
    "file = \"ready_for_karp_v2.csv\"\n",
    "\n",
    "df = pd.read_csv(path+file)\n",
    "\n",
    "df = df[df[\"status\"] == \"automatically verified\"].copy().drop_duplicates()\n",
    "\n",
    "\n",
    "df = df.groupby([\"English lemma\", \"POS\", \"status\"])[\"Swedish lemma\"].agg(lambda x: ';'.join(x)).reset_index()\n",
    "\n",
    "df[df[\"Swedish lemma\"].str.contains(\";\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[~df2[\"English lemma\"].isin(df[\"English lemma\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Swedish lemma\"].str.contains(\";\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts = df2.to_dict(orient='records')\n",
    "\n",
    "new_list = []\n",
    "\n",
    "for item in list_of_dicts:\n",
    "\n",
    "    swedish_translations = item[\"Swedish lemma\"].split(\";\")\n",
    "    new_item = {\n",
    "        \"eng\": {\n",
    "            \"lemma\": item[\"English lemma\"]\n",
    "        },\n",
    "        \"swe\": {\n",
    "            \"lemma\": swedish_translations[0]\n",
    "        },\n",
    "        \"src\": \"paired-keywords\",\n",
    "        \"pos\": item[\"POS\"]\n",
    "    }\n",
    "    if len(swedish_translations) > 1:\n",
    "        new_item[\"synonyms\"] = swedish_translations[1:]\n",
    "    new_list.append(new_item)\n",
    "\n",
    "print(len(new_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "added = 0\n",
    "authorization = json.load(open('../../data/secrets.json')).get(\"jwt_token\", \"\")\n",
    "for j, entry in enumerate(new_list[694:]):\n",
    "    \n",
    "    res = add_entry(authorization, entry)\n",
    "    \n",
    "    if res is not None:\n",
    "        added += 1\n",
    "\n",
    "    if j % 300 == 0:\n",
    "        print(added, j+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = add_entries(authorization, entries)\n",
    "true_count = res.count(True)\n",
    "print(\"Number of sucessfull requests:\", true_count)\n",
    "print(\"Number of requests:\", len(res))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
